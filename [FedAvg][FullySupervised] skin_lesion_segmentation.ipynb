{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca7dbedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import functional as F\n",
    "from unet import UNet\n",
    "from dice_loss import dice_coeff\n",
    "####################################################\n",
    "# for data splitting\n",
    "####################################################\n",
    "import pandas as pd\n",
    "####################################################\n",
    "# for data preparation\n",
    "####################################################\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, balanced_accuracy_score\n",
    "####################################################\n",
    "# for plotting\n",
    "####################################################\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "############################\n",
    "# Helper func\n",
    "############################\n",
    "from helper import * \n",
    "###################################\n",
    "TRAIN_RATIO = 0.8\n",
    "RS = 30448\n",
    "N_CHANNELS, N_CLASSES = 1, 1 \n",
    "bilinear = True\n",
    "BATCH_SIZE, EPOCHS = 16, 150\n",
    "IMAGE_SIZE = (600, 600)\n",
    "CROP_SIZE = (600, 600)\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=1-TRAIN_RATIO, random_state=RS)\n",
    "\n",
    "#There are 7 types of classes in the dataset for lesions as specified:\n",
    "lesion_type_dict = {\n",
    "    'seg': 'Segmentation', # 0\n",
    "}\n",
    "lesion_type_dict_malignant = {\n",
    "    'seg': 'ben', # 0\n",
    "}\n",
    "#########################################\n",
    "DIR = 'data/'\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "886ff19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.multiprocessing\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30674cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miccai\n",
      "bns\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "CLIENTS = ['miccai', 'bns']\n",
    "CLIENTS_2 = [cl + '_2' for cl in CLIENTS]\n",
    "###################################################################\n",
    "TOTAL_CLIENTS = len(CLIENTS)\n",
    "\n",
    "DIR_DATA = 'data/imagesTrAug/'\n",
    "DIR_GT = 'data/labelsTrBW/'\n",
    "\n",
    "# Costruire una lista dei nomi dei file per ciascun nuovo dataset.\n",
    "skin_dataset = dict()\n",
    "skin_dataset['miccai'] = ['miccai_{:03d}'.format(i) for i in range(1, 201)]  # Nomi dei file per il dataset \"miccai\"\n",
    "skin_dataset['bns'] = ['bns_{:03d}'.format(i) for i in range(1, 181)]  # Nomi dei file per il dataset \"bns\"\n",
    "\n",
    "split_dataset = dict()\n",
    "STATIC_WEIGHT = [0, 0]\n",
    "order = 0\n",
    "\n",
    "for client in skin_dataset:\n",
    "    tmp = skin_dataset[client]\n",
    "    x_ = [os.path.join(DIR_DATA, f + '.png') for f in tmp]\n",
    "    y_ = [os.path.join(DIR_GT, f + '.png') for f in tmp]\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x_, y_, test_size=1 - TRAIN_RATIO, random_state=RS)\n",
    "\n",
    "    split_dataset[client + '_train'] = Cancer(x_train, y_train, train=True, \\\n",
    "                                              IMAGE_SIZE=IMAGE_SIZE \\\n",
    "                                              , CROP_SIZE=CROP_SIZE)\n",
    "    STATIC_WEIGHT[order] = len(x_train)\n",
    "    order += 1\n",
    "\n",
    "    split_dataset[client + '_test'] = Cancer(x_test, y_test, train=False, \\\n",
    "                                             IMAGE_SIZE=IMAGE_SIZE \\\n",
    "                                             , CROP_SIZE=CROP_SIZE)\n",
    "    print(client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9fc254ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5263157894736842, 0.47368421052631576]\n"
     ]
    }
   ],
   "source": [
    "STATIC_WEIGHT = [item / sum(STATIC_WEIGHT) for item in STATIC_WEIGHT]\n",
    "print(STATIC_WEIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bbdd5120",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "LR, WD, TH = 1e-3, 1e-4, 0.9\n",
    "best_avg_acc, best_epoch = 0.0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3223805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miccai\n",
      "bns\n"
     ]
    }
   ],
   "source": [
    "training_clients, testing_clients = dict(), dict()\n",
    "training_clients_pl = dict()\n",
    "\n",
    "acc_train, acc_test, loss_train, loss_test = dict(), dict(), \\\n",
    "                                            dict(), dict()\n",
    "    \n",
    "nets, optimizers = dict(), dict()\n",
    "\n",
    "nets['global'] = UNet(n_channels=N_CHANNELS, n_classes=N_CLASSES, \\\n",
    "                      bilinear=True).to(device)\n",
    "\n",
    "nets['global_2'] = UNet(n_channels=N_CHANNELS, n_classes=N_CLASSES, \\\n",
    "                      bilinear=True).to(device)\n",
    "\n",
    "for client in CLIENTS:\n",
    "    print(client)\n",
    "    training_clients[client] = DataLoader(split_dataset[client+'_train'], batch_size=2,\\\n",
    "                 shuffle=True, num_workers=8)\n",
    "    training_clients_pl[client] = DataLoader(split_dataset[client+'_train'], batch_size=1, \\\n",
    "                shuffle=True, num_workers=8)\n",
    "    ###################################################################################\n",
    "    testing_clients[client] = DataLoader(split_dataset[client+'_test'], batch_size=1,\\\n",
    "                         shuffle=False, num_workers=1)\n",
    "    \n",
    "    acc_train[client], acc_test[client] = [], []\n",
    "    loss_train[client], loss_test[client] = [], []\n",
    "        \n",
    "    nets[client] = UNet(n_channels=N_CHANNELS, n_classes=N_CLASSES, \\\n",
    "                      bilinear=True).to(device)\n",
    "    nets[client+'_2'] = UNet(n_channels=N_CHANNELS, n_classes=N_CLASSES, \\\n",
    "                      bilinear=True).to(device)\n",
    "    optimizers[client]= optim.Adam(nets[client].parameters(), \\\n",
    "                                   lr=LR,weight_decay=WD)\n",
    "    optimizers[client+'_2']= optim.Adam(nets[client+'_2'].parameters(), \\\n",
    "                                   lr=LR,weight_decay=WD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c716dd4-1545-46dc-a332-7f4317be816f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: miccai_train\n",
      "Value:\n",
      "  - Sample 1\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 2\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 3\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 4\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 5\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 6\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 7\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 8\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 9\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 10\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "\n",
      "\n",
      "Key: miccai_test\n",
      "Value:\n",
      "  - Sample 1\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 2\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 3\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 4\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 5\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 6\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 7\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 8\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 9\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 10\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "\n",
      "\n",
      "Key: bns_train\n",
      "Value:\n",
      "  - Sample 1\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 2\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 3\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 4\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 5\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 6\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 7\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 8\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 9\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 10\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "\n",
      "\n",
      "Key: bns_test\n",
      "Value:\n",
      "  - Sample 1\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 2\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 3\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 4\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 5\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 6\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 7\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 8\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 9\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 10\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stampa 10 esempi di contenuto di split_dataset\n",
    "for i, (key, value) in enumerate(split_dataset.items()):\n",
    "    if i >= 10:\n",
    "        break\n",
    "    print(\"Key:\", key)\n",
    "    print(\"Value:\")\n",
    "    for j in range(min(10, len(value))):\n",
    "        x, y, bbox_mask = value[j]\n",
    "        print(\"  - Sample\", j+1)\n",
    "        print(\"    - Image shape:\", x.shape)\n",
    "        print(\"    - Label shape:\", y.shape)\n",
    "        print(\"    - BBox mask shape:\", bbox_mask.shape)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a48e6cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENTS_SUPERVISION = ['labeled', 'labeled']\n",
    "# CLIENTS_SUPERVISION = ['unlabeled', 'unlabeled', 'labeled', 'unlabeled']\n",
    "# CLIENTS_SUPERVISION = ['bbox','bbox','labeled', 'bbox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7773cb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_supervision = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7524c195",
   "metadata": {},
   "source": [
    "# FedAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6bdbe97",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENTS_SUPERVISION = ['labeled', 'labeled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "586f2f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS = STATIC_WEIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d549aaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "best_model_dir = \"C:\\\\Users\\\\utente\\\\Desktop\"\n",
    "\n",
    "best_avg_acc, best_epoch_avg = 0, 0\n",
    "best_models = {}  # Dizionario per memorizzare i migliori modelli per ciascun cliente\n",
    "\n",
    "for epoch in range(EPOCHS):        \n",
    "    index.append(epoch)\n",
    "    \n",
    "    #################### copy fed model ###################\n",
    "    copy_fed(CLIENTS, nets, fed_name='global')\n",
    "    \n",
    "    #### conduct training #####\n",
    "    for client, supervision_t in zip(CLIENTS, CLIENTS_SUPERVISION):\n",
    "        train_model(training_clients[client], nets[client], \\\n",
    "                                  optimizers[client], device, \\\n",
    "                                  acc = acc_train[client], \\\n",
    "                                  loss = loss_train[client], \\\n",
    "                                  supervision_type = supervision_t)\n",
    "        \n",
    "    aggr_fed(CLIENTS, WEIGHTS, nets, fed_name='global')\n",
    "    ################### test ##############################\n",
    "    avg_acc = 0.0\n",
    "    for client in CLIENTS:\n",
    "        test(epoch, testing_clients[client], nets['global'], device, acc_test[client],\\\n",
    "             loss_test[client])\n",
    "        avg_acc += acc_test[client][-1]\n",
    "        \n",
    "        # Salva il modello se l'accuratezza del cliente migliora\n",
    "        if acc_test[client][-1] > best_models.get(client, {'accuracy': 0})['accuracy']:\n",
    "            best_models[client] = {'model': nets[client].state_dict(), 'accuracy': acc_test[client][-1]}\n",
    "            torch.save(nets[client].state_dict(), os.path.join(best_model_dir, f\"best_model_{client}.pt\"))\n",
    "        \n",
    "    avg_acc = avg_acc / TOTAL_CLIENTS\n",
    "    ############################################################\n",
    "    ########################################################\n",
    "    if avg_acc > best_avg_acc:\n",
    "        best_avg_acc = avg_acc\n",
    "        best_epoch = epoch\n",
    "    \n",
    "    ################################\n",
    "    # plot #########################\n",
    "    ################################\n",
    "    clear_output(wait=True)\n",
    "    print(\"Epoch:\", epoch, \"/\", EPOCHS)\n",
    "    print(\"Current Average Accuracy:\", avg_acc, \"Best Average Accuracy:\", best_avg_acc)\n",
    "    plot_graphs(0, CLIENTS, index, acc_train, 'acc_train')\n",
    "    plot_graphs(1, CLIENTS, index, loss_train, 'loss_train')\n",
    "    plot_graphs(2, CLIENTS, index, acc_test, ' acc_test')\n",
    "\n",
    "print(\"Best Average Accuracy:\", best_avg_acc, \"at Epoch:\", best_epoch)\n",
    "for client in CLIENTS:\n",
    "    print(client)\n",
    "    tmp = best_epoch\n",
    "    best_epoch = best_epoch \n",
    "    print(\"shared epoch specific\")\n",
    "    print(acc_test[client][best_epoch])\n",
    "    print(\"max client-specific\")\n",
    "    print(np.max(acc_test[client]))\n",
    "    best_epoch = tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9236aee-ddba-4d3e-8301-503094d9cd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Funzione per caricare un'immagine di test\n",
    "def load_test_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    return image\n",
    "\n",
    "# Funzione per visualizzare l'immagine e la segmentazione ottenuta dal modello\n",
    "def visualize(image, segmentation):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    axes[0].imshow(image)\n",
    "    axes[0].set_title('Test Image')\n",
    "    axes[0].axis('off')\n",
    "    axes[1].imshow(segmentation, cmap='gray')\n",
    "    axes[1].set_title('Segmentation')\n",
    "    axes[1].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Percorso della directory contenente i modelli salvati\n",
    "saved_models_dir = \"C:\\\\Users\\\\utente\\\\Desktop\"\n",
    "\n",
    "# Cliente per cui è stato salvato il modello\n",
    "client = \"miccai\"\n",
    "\n",
    "# Carica il modello salvato per il cliente specificato\n",
    "model_path = os.path.join(saved_models_dir, f\"best_model_{client}.pt\")\n",
    "if os.path.exists(model_path):\n",
    "    model = YourModel()  # Sostituisci YourModel() con la classe/modello specifico che hai utilizzato\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "else:\n",
    "    print(f\"Model for client {client} not found at {model_path}\")\n",
    "\n",
    "# Percorso dell'immagine di test\n",
    "test_image_path = \"C:\\Users\\utente\\Desktop\\Università\\Tesi magistrale\\RC Nuclei Cellulari\\RC_Nuclei\\Nuclei_Segmentation_Experiments_Demo_dataset\\MICCAI2017\\Nuclei_segmentation_testing\\imagesTs\\image02.png\"  # Sostituisci con il percorso dell'immagine di test\n",
    "\n",
    "# Carica l'immagine di test\n",
    "test_image = load_test_image(test_image_path)\n",
    "\n",
    "# Esegui la segmentazione sull'immagine di test utilizzando il modello caricato\n",
    "if model:\n",
    "    # Assicurati di adattare questa parte del codice in base alla tua implementazione specifica\n",
    "    with torch.no_grad():\n",
    "        # Preprocessa l'immagine di test se necessario\n",
    "        preprocessed_image = preprocess(test_image)\n",
    "        # Effettua la segmentazione\n",
    "        segmentation_output = model(preprocessed_image)\n",
    "        # Postprocessa la segmentazione se necessario\n",
    "        postprocessed_segmentation = postprocess(segmentation_output)\n",
    "    \n",
    "    # Visualizza l'immagine di test e la segmentazione ottenuta\n",
    "    visualize(test_image, postprocessed_segmentation)\n",
    "else:\n",
    "    print(\"Model not found for client 'miccai'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
