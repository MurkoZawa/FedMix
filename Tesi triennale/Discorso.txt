La mia trattazione di tesi riguarda l'impiego di tecniche di apprendimento e classificazione per classificare correttamente immagini istopatologiche.
Il tumore gastrico è il quinto tumore più comune che ci sia al mondo, nonché il quarto più letale. I medici hanno spesso avuto delle difficoltà a
diagnosticare in modo corretto la patologia, sia per la varianza imprevedibile dei parametri patobiologici da paziente a paziente, sia per il grande 
carico di lavoro a cui sono sottoposti ogni giorno, portandoli frequentemente a diagnosi errate.
La tecnologia informatica si è evoluta al punto da poter assistere i medici a diagnosticare in modo più accurato e con meno margine di errore, mediante
l'utilizzo di particolari tecniche di apprendimento: ML e DL.

In questo lavoro si è cercato di ottimizzare tali tecniche per classificare le immagini della patologia nel modo più accurato possibile.
Per farlo è stato preso in esame il dataset GasHisSDB, Gastric Histopathology Sub-size Image Database, studiato nel documento riportato nella slide. 
Tale dataset è un insieme di immagini della patologia di tre dimensioni diverse: 160, 120 e 80; catalogate in due classi differenti: la classe "Normale", 
contenente immagini di cellule e tessuti sani, come si vede nell'immagine in alto; e la classe "Anormale", contenente immagini aventi più del 50% di aree 
cancerogene, come si vede in quella in basso. Inizialmente è stato preso in esame il dataset da 160.

Di seguito sono riportate le varie feature che sono state estratte per favorire l'apprendimento: per quanto concerne le feature handcrafted
sono state trattate le feature della texture, di colore e i momenti invarianti; mentre per le feature deep sono state estratte le attivazioni delle
reti neurali qui citate.

Tali feature sono state utilizzate per addestrare cinque classificatori diversi: kNN, Fine Tree, Random Forest, Ensemble ed SVM e originare dei modelli.
Per calcolare i risultati, sono state generate per tali modelli addestrati le matrici di confusione, da cui sono state estratte le statistiche per ogni metrica
presente in queste tabelle. Sono stati presi in considerazione soprattutto i valori assunti dall’F-Score, perché è la metrica che prende in 
esame Precision e Recall, e si può dire che è quella che descrive al meglio il modello. Nella prima tabella è rappresentata la miglior feature handcrafted, ovvero
i momenti di Chebishev di seconda specie di sesto grado, che ha ottenuto il miglior rendimento, infatti ha ottenuto valori anche sopra l'80%. In coppia con
l'Ensemble, raggiunge l'84%, miglior risultato fra tutte le feature di questo tipo. Nella seconda sono riportate le due feature deep più efficienti, che hanno prodotto
risultati ancora più soddisfacenti: DenseNet 201 ed EfficientNet-b0, con valori che superano anche il 90%. In particolare, DenseNet 201 usata per addestrare l'SVM, 
supera il 95% di F-Score.

Inoltre si è effettuato un affinamento al fine di migliorare ancora le prestazioni: la combinazione tra feature. Si sono considerate le feature appena viste nelle tabelle precedenti
e si sono combinate fra loro in ogni possibile modo. I risultati, in questo modo, sono stati ulteriormente raffinati. Nell'asse delle ascisse notiamo le feature combinate
e in quello delle ordinate il valore di F-Score. Tutti i valori sfiorano o superano notevolmente il 90%. Addirittura, la tripla combinazione, sfiora il 96%.

Per verificare l'efficienza dei modelli addestrati nel dataset di immagini 160x160; si è deciso di sperimentare gli stessi modelli per classificare immagini
istopatologiche di risoluzioni differenti: 120x120 e 80x80.
Per il primo subset il rendimento è stato molto buono, i valori sono compresi tra l'86% e il 92%. Per il secondo, i risultati sono accettabili, ma
inferiori ai precedenti. Sicuramente questo è accaduto per via della numerosità notevole di immagini e per la loro crescente complessità, che ha reso la
classificazione con modelli addestrati più tortuosa.

Come abbiamo visto, questo lavoro prevedeva due task principali: la classificazione di immagini 160x160 e la sperimentazione cross-dataset.
Analizzando tutti i risultati ottenuti, si evince che il classificatore che ha avuto il rendimento migliore è indubbiamente il Random Forest, per il
quale si consiglia un approccio basato sul suo addestramento mediante le seguenti feature: per il primo task CH, CH2, LM come feature handcrafted,
poiché si sono ottenuti sempre valori maggiori dell'80%; le feature deep DarkNet 53, DenseNet 201, EfficientNet-b0, Inception-ResNet-v2, avendo portato a valori
maggiori del 90%; e le feature combinate CHd6-DenseNet 201-EfficientNet-b0 per prestazioni ancora più elevate. Per il secondo task, si consiglia
la combinazione tra DenseNet 201 ed EfficientNet-b0, avendo riscontrato risultati maggiori dell'80% per immagini 80x80 e maggiori del 90% per immagini
120x120.

Perciò, si può concludere che la combinazione tra feature ha ulteriormente raffinato i risultati; sono stati ottenuti valori complessivamente maggiori
di quelli ottenuti dagli autori del documento citato nella slide, essendo superiori al 95% e avendoli superati del 10%; i modelli del dataset di immagini
da 160 sono affidabili anche per immagini di altre risoluzioni; e l'obiettivo si può dire sia stato raggiunto con successo.

Gli sviluppi futuri a partire da questo lavoro sono molteplici: si estenderà la classificazione su ulteriori feature e classificatori, andando a
includere VT di nuova generazione; e sviluppi addizionali riguardanti la problematica cross-dataset saranno realizzati per mezzo di test
e raffinamenti su nuovi dataset e differenti tipologie di colorazione.

Grazie a tutti per l'attenzione.
