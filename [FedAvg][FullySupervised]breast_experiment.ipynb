{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faf647e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import functional as F\n",
    "from unet import UNet\n",
    "from dice_loss import dice_coeff\n",
    "\n",
    "####################################################\n",
    "# for data preparation\n",
    "####################################################\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, balanced_accuracy_score\n",
    "####################################################\n",
    "# for plotting\n",
    "####################################################\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "############################\n",
    "# Helper func\n",
    "############################\n",
    "from helper import * \n",
    "#################################\n",
    "N_CHANNELS, N_CLASSES = 1, 1 \n",
    "bilinear = True\n",
    "BATCH_SIZE, EPOCHS = 16, 300\n",
    "IMAGE_SIZE = (256, 256)\n",
    "CROP_SIZE = (224, 224)\n",
    "#########################################\n",
    "DIR = 'dataset/breast'\n",
    "CLIENTS = ['miccai', 'bns']\n",
    "CLIENTS_2 = [cl +'_2' for cl in CLIENTS]\n",
    "TOTAL_CLIENTS = len(CLIENTS)\n",
    "#####################################\n",
    "# add the classification segment ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91cc0b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "LR, WD = 1e-3, 1e-4\n",
    "\n",
    "LAM, BETA, TH = 10, 1.5,0.9\n",
    "VERSION = 1\n",
    "CLIENTS_SUPERVISION = ['labeled', 'labeled']\n",
    "WEIGHTS_CL = [0.0, 0.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8560533f",
   "metadata": {},
   "source": [
    "# load training-test path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04b6a5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full training data\n",
      "Full training data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "\n",
    "# Definisci il percorso delle cartelle delle immagini e delle etichette\n",
    "IMAGES_DIR = \"C:/Users/utente/Desktop/Università/Tesi magistrale/FedMix/data/imagesTrGray\"\n",
    "LABELS_DIR = \"C:/Users/utente/Desktop/Università/Tesi magistrale/FedMix/data/labelsTrGray\"\n",
    "\n",
    "breast_dataset = dict()\n",
    "idx_ = 0\n",
    "denom_ = 0\n",
    "\n",
    "for client, sup in zip(CLIENTS, CLIENTS_SUPERVISION):\n",
    "    # Carica le immagini e le etichette dal percorso specificato\n",
    "    x_train = glob.glob(os.path.join(IMAGES_DIR, \"*.png\"))\n",
    "    y_train = glob.glob(os.path.join(LABELS_DIR, \"*.png\"))\n",
    "\n",
    "    # Se il cliente non ha supervisione, aggiungi anche le immagini normali\n",
    "    if sup == 'unlabeled':\n",
    "        DATA_TYPE = ['original', 'GT']\n",
    "        for data in DATA_TYPE:\n",
    "            # Carica le immagini normali\n",
    "            normal_images = glob.glob(os.path.join(IMAGES_DIR, \"miccai\", \"classification\", data, \"normal*.jpg\"))\n",
    "            if data == 'GT':\n",
    "                y_train += normal_images\n",
    "            else:\n",
    "                x_train += normal_images\n",
    "\n",
    "    # Scegli casualmente il 10% delle immagini e delle etichette come set di test\n",
    "    num_test_samples = int(0.1 * len(x_train))\n",
    "    test_indices = random.sample(range(len(x_train)), num_test_samples)\n",
    "    x_test = [x_train[i] for i in test_indices]\n",
    "    y_test = [y_train[i] for i in test_indices]\n",
    "    x_train = [x_train[i] for i in range(len(x_train)) if i not in test_indices]\n",
    "    y_train = [y_train[i] for i in range(len(y_train)) if i not in test_indices]\n",
    "\n",
    "    print('Full training data')\n",
    "    WEIGHTS_CL[idx_] = len(x_train)\n",
    "    denom_ += len(x_train)\n",
    "    idx_ += 1\n",
    "    \n",
    "    # Carica il dataset utilizzando la classe Cancer (assicurati di avere la definizione di questa classe)\n",
    "    breast_dataset[client+'_train'] = Cancer(x_train, y_train, train=True,\\\n",
    "                                             IMAGE_SIZE=IMAGE_SIZE, CROP_SIZE=CROP_SIZE)\n",
    "\n",
    "    # Carica il dataset di test\n",
    "    breast_dataset[client+'_test'] = Cancer(x_test, y_test, train=False,\\\n",
    "                                            IMAGE_SIZE=IMAGE_SIZE, CROP_SIZE=CROP_SIZE)\n",
    "\n",
    "# Normalizza i pesi dei clienti\n",
    "for idx_ in range(len(WEIGHTS_CL)):\n",
    "    WEIGHTS_CL[idx_] = WEIGHTS_CL[idx_]/denom_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e967240b",
   "metadata": {},
   "source": [
    "# storage file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daa76ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_clients, testing_clients = dict(), dict()\n",
    "training_clients_pl = dict()\n",
    "\n",
    "acc_train, acc_test, loss_train, loss_test = dict(), dict(), \\\n",
    "                                            dict(), dict()\n",
    "    \n",
    "nets, optimizers = dict(), dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ad0cc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "nets['global'] = UNet(n_channels=N_CHANNELS, n_classes=N_CLASSES, \\\n",
    "                      bilinear=True).to(device)\n",
    "\n",
    "nets['global_2'] = UNet(n_channels=N_CHANNELS, n_classes=N_CLASSES, \\\n",
    "                      bilinear=True).to(device)\n",
    "\n",
    "for client in CLIENTS:\n",
    "    training_clients[client] = DataLoader(breast_dataset[client+'_train'], batch_size=16,\\\n",
    "                 shuffle=True, num_workers=8)\n",
    "    training_clients_pl[client] = DataLoader(breast_dataset[client+'_train'], batch_size=1, \\\n",
    "                shuffle=True, num_workers=8)\n",
    "    ###################################################################################\n",
    "    testing_clients[client] = DataLoader(breast_dataset[client+'_test'], batch_size=1,\\\n",
    "                         shuffle=False, num_workers=1)\n",
    "    \n",
    "    acc_train[client], acc_test[client] = [], []\n",
    "    loss_train[client], loss_test[client] = [], []\n",
    "        \n",
    "    nets[client] = UNet(n_channels=N_CHANNELS, n_classes=N_CLASSES, \\\n",
    "                      bilinear=True).to(device)\n",
    "    nets[client+'_2'] = UNet(n_channels=N_CHANNELS, n_classes=N_CLASSES, \\\n",
    "                      bilinear=True).to(device)\n",
    "    optimizers[client]= optim.Adam(nets[client].parameters(), \\\n",
    "                                   lr=LR,weight_decay=WD)\n",
    "    optimizers[client+'_2']= optim.Adam(nets[client+'_2'].parameters(), \\\n",
    "                                   lr=LR,weight_decay=WD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a52fbb5",
   "metadata": {},
   "source": [
    "## FedAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96d5781",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_avg_acc, best_epoch_avg = 0, 0\n",
    "index = []\n",
    "\n",
    "for client in CLIENTS:\n",
    "    acc_train[client], acc_test[client] = [], []\n",
    "    loss_train[client], loss_test[client] = [], []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    index.append(epoch)\n",
    "    #################### copy fed model ###################\n",
    "    copy_fed(CLIENTS, nets, fed_name='global')\n",
    "    \n",
    "    #### conduct training #####\n",
    "    for client, supervision_t in zip(CLIENTS, CLIENTS_SUPERVISION):\n",
    "        train_model(training_clients[client], nets[client], \\\n",
    "                                  optimizers[client], device, \\\n",
    "                                  acc = acc_train[client], \\\n",
    "                                  loss = loss_train[client], \\\n",
    "                                  supervision_type = supervision_t)\n",
    "        \n",
    "    aggr_fed(CLIENTS, WEIGHTS_CL, nets, fed_name='global')\n",
    "    ################### test ##############################\n",
    "    avg_acc = 0.0\n",
    "    for client in CLIENTS:\n",
    "        test(epoch, testing_clients[client], nets['global'], device, acc_test[client],\\\n",
    "             loss_test[client])\n",
    "        avg_acc += acc_test[client][-1]\n",
    "        \n",
    "    avg_acc = avg_acc / TOTAL_CLIENTS\n",
    "    ############################################################\n",
    "    ########################################################\n",
    "    if avg_acc > best_avg_acc:\n",
    "        best_avg_acc = avg_acc\n",
    "        best_epoch = epoch\n",
    "    \n",
    "    ################################\n",
    "    # plot #########################\n",
    "    ################################\n",
    "    clear_output(wait=True)\n",
    "    print(avg_acc, best_avg_acc)\n",
    "    plt.figure(0)\n",
    "    plt.plot(index, acc_train['miccai'], colors[1], label='miccai train')\n",
    "    plt.plot(index, acc_train['bns'], colors[2], label='bns train')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(1)\n",
    "    plt.plot(index, loss_train['miccai'], colors[1], label='miccai loss train')\n",
    "    plt.plot(index, loss_train['bns'], colors[2], label='bns loss train')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    plot_graphs(2, CLIENTS, index, acc_test, ' acc_test')\n",
    "\n",
    "print(best_avg_acc, best_epoch)\n",
    "for client in CLIENTS:\n",
    "    print(client)\n",
    "    tmp = best_epoch\n",
    "    best_epoch = best_epoch \n",
    "    print(\"shared epoch specific\")\n",
    "    print(acc_test[client][best_epoch])\n",
    "    print(\"max client-specific\")\n",
    "    print(np.max(acc_test[client]))\n",
    "    best_epoch = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db7d738-e508-4548-a579-d0994a49bfa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82951d55-7ea8-4075-b7c4-7ce85a6c7bdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
