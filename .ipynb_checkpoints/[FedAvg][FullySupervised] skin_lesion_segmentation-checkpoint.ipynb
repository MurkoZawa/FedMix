{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca7dbedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import functional as F\n",
    "from unet import UNet\n",
    "from dice_loss import dice_coeff\n",
    "####################################################\n",
    "# for data splitting\n",
    "####################################################\n",
    "import pandas as pd\n",
    "####################################################\n",
    "# for data preparation\n",
    "####################################################\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, balanced_accuracy_score\n",
    "####################################################\n",
    "# for plotting\n",
    "####################################################\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "############################\n",
    "# Helper func\n",
    "############################\n",
    "from helper import * \n",
    "###################################\n",
    "TRAIN_RATIO = 0.8\n",
    "RS = 30448\n",
    "N_CHANNELS, N_CLASSES = 1, 1 \n",
    "bilinear = True\n",
    "BATCH_SIZE, EPOCHS = 16, 150\n",
    "IMAGE_SIZE = (600, 600)\n",
    "CROP_SIZE = (600, 600)\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=1-TRAIN_RATIO, random_state=RS)\n",
    "\n",
    "#There are 7 types of classes in the dataset for lesions as specified:\n",
    "lesion_type_dict = {\n",
    "    'seg': 'Segmentation', # 0\n",
    "}\n",
    "lesion_type_dict_malignant = {\n",
    "    'seg': 'ben', # 0\n",
    "}\n",
    "#########################################\n",
    "DIR = 'data/'\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "886ff19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.multiprocessing\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30674cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miccai\n",
      "bns\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "CLIENTS = ['miccai', 'bns']\n",
    "CLIENTS_2 = [cl + '_2' for cl in CLIENTS]\n",
    "###################################################################\n",
    "TOTAL_CLIENTS = len(CLIENTS)\n",
    "\n",
    "DIR_DATA = 'data/imagesTrAug/'\n",
    "DIR_GT = 'data/labelsTrBW/'\n",
    "\n",
    "# Costruire una lista dei nomi dei file per ciascun nuovo dataset.\n",
    "skin_dataset = dict()\n",
    "skin_dataset['miccai'] = ['miccai_{:03d}'.format(i) for i in range(1, 201)]  # Nomi dei file per il dataset \"miccai\"\n",
    "skin_dataset['bns'] = ['bns_{:03d}'.format(i) for i in range(1, 181)]  # Nomi dei file per il dataset \"bns\"\n",
    "\n",
    "split_dataset = dict()\n",
    "STATIC_WEIGHT = [0, 0]\n",
    "order = 0\n",
    "\n",
    "for client in skin_dataset:\n",
    "    tmp = skin_dataset[client]\n",
    "    x_ = [os.path.join(DIR_DATA, f + '.png') for f in tmp]\n",
    "    y_ = [os.path.join(DIR_GT, f + '.png') for f in tmp]\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x_, y_, test_size=1 - TRAIN_RATIO, random_state=RS)\n",
    "\n",
    "    split_dataset[client + '_train'] = Cancer(x_train, y_train, train=True, \\\n",
    "                                              IMAGE_SIZE=IMAGE_SIZE \\\n",
    "                                              , CROP_SIZE=CROP_SIZE)\n",
    "    STATIC_WEIGHT[order] = len(x_train)\n",
    "    order += 1\n",
    "\n",
    "    split_dataset[client + '_test'] = Cancer(x_test, y_test, train=False, \\\n",
    "                                             IMAGE_SIZE=IMAGE_SIZE \\\n",
    "                                             , CROP_SIZE=CROP_SIZE)\n",
    "    print(client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9fc254ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5263157894736842, 0.47368421052631576]\n"
     ]
    }
   ],
   "source": [
    "STATIC_WEIGHT = [item / sum(STATIC_WEIGHT) for item in STATIC_WEIGHT]\n",
    "print(STATIC_WEIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bbdd5120",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "LR, WD, TH = 1e-3, 1e-4, 0.9\n",
    "best_avg_acc, best_epoch = 0.0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3223805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miccai\n",
      "bns\n"
     ]
    }
   ],
   "source": [
    "training_clients, testing_clients = dict(), dict()\n",
    "training_clients_pl = dict()\n",
    "\n",
    "acc_train, acc_test, loss_train, loss_test = dict(), dict(), \\\n",
    "                                            dict(), dict()\n",
    "    \n",
    "nets, optimizers = dict(), dict()\n",
    "\n",
    "nets['global'] = UNet(n_channels=N_CHANNELS, n_classes=N_CLASSES, \\\n",
    "                      bilinear=True).to(device)\n",
    "\n",
    "nets['global_2'] = UNet(n_channels=N_CHANNELS, n_classes=N_CLASSES, \\\n",
    "                      bilinear=True).to(device)\n",
    "\n",
    "for client in CLIENTS:\n",
    "    print(client)\n",
    "    training_clients[client] = DataLoader(split_dataset[client+'_train'], batch_size=2,\\\n",
    "                 shuffle=True, num_workers=8)\n",
    "    training_clients_pl[client] = DataLoader(split_dataset[client+'_train'], batch_size=1, \\\n",
    "                shuffle=True, num_workers=8)\n",
    "    ###################################################################################\n",
    "    testing_clients[client] = DataLoader(split_dataset[client+'_test'], batch_size=1,\\\n",
    "                         shuffle=False, num_workers=1)\n",
    "    \n",
    "    acc_train[client], acc_test[client] = [], []\n",
    "    loss_train[client], loss_test[client] = [], []\n",
    "        \n",
    "    nets[client] = UNet(n_channels=N_CHANNELS, n_classes=N_CLASSES, \\\n",
    "                      bilinear=True).to(device)\n",
    "    nets[client+'_2'] = UNet(n_channels=N_CHANNELS, n_classes=N_CLASSES, \\\n",
    "                      bilinear=True).to(device)\n",
    "    optimizers[client]= optim.Adam(nets[client].parameters(), \\\n",
    "                                   lr=LR,weight_decay=WD)\n",
    "    optimizers[client+'_2']= optim.Adam(nets[client+'_2'].parameters(), \\\n",
    "                                   lr=LR,weight_decay=WD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c716dd4-1545-46dc-a332-7f4317be816f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: miccai_train\n",
      "Value:\n",
      "  - Sample 1\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 2\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 3\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 4\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 5\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 6\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 7\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 8\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 9\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 10\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "\n",
      "\n",
      "Key: miccai_test\n",
      "Value:\n",
      "  - Sample 1\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 2\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 3\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 4\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 5\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 6\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 7\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 8\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 9\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 10\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "\n",
      "\n",
      "Key: bns_train\n",
      "Value:\n",
      "  - Sample 1\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 2\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 3\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 4\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 5\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 6\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 7\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 8\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 9\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 10\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "\n",
      "\n",
      "Key: bns_test\n",
      "Value:\n",
      "  - Sample 1\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 2\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 3\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 4\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 5\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 6\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 7\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 8\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 9\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "  - Sample 10\n",
      "    - Image shape: torch.Size([1, 600, 600])\n",
      "    - Label shape: torch.Size([1, 600, 600])\n",
      "    - BBox mask shape: torch.Size([1, 600, 600])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stampa 10 esempi di contenuto di split_dataset\n",
    "for i, (key, value) in enumerate(split_dataset.items()):\n",
    "    if i >= 10:\n",
    "        break\n",
    "    print(\"Key:\", key)\n",
    "    print(\"Value:\")\n",
    "    for j in range(min(10, len(value))):\n",
    "        x, y, bbox_mask = value[j]\n",
    "        print(\"  - Sample\", j+1)\n",
    "        print(\"    - Image shape:\", x.shape)\n",
    "        print(\"    - Label shape:\", y.shape)\n",
    "        print(\"    - BBox mask shape:\", bbox_mask.shape)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a48e6cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENTS_SUPERVISION = ['labeled', 'labeled']\n",
    "# CLIENTS_SUPERVISION = ['unlabeled', 'unlabeled', 'labeled', 'unlabeled']\n",
    "# CLIENTS_SUPERVISION = ['bbox','bbox','labeled', 'bbox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7773cb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_supervision = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7524c195",
   "metadata": {},
   "source": [
    "# FedAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6bdbe97",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENTS_SUPERVISION = ['labeled', 'labeled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "586f2f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS = STATIC_WEIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d549aaaa",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#### conduct training #####\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m client, supervision_t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(CLIENTS, CLIENTS_SUPERVISION):\n\u001b[1;32m---> 17\u001b[0m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_clients\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m                              \u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m                              \u001b[49m\u001b[43macc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43macc_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mloss_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m                              \u001b[49m\u001b[43msupervision_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msupervision_t\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m aggr_fed(CLIENTS, WEIGHTS, nets, fed_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglobal\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m################### test ##############################\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\Università\\Tesi magistrale\\FedMix\\helper.py:484\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(trainloader, net_stu, optimizer_stu, device, acc, loss, supervision_type, warmup, CE_LOSS, FedMix_network)\u001b[0m\n\u001b[0;32m    482\u001b[0m         l_ \u001b[38;5;241m=\u001b[39m l_stu\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m#############################\u001b[39;00m\n\u001b[1;32m--> 484\u001b[0m \u001b[43ml_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    485\u001b[0m optimizer_stu\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# for evaluation \u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "best_model_dir = \"C:\\\\Users\\\\utente\\\\Desktop\"\n",
    "\n",
    "best_avg_acc, best_epoch_avg = 0, 0\n",
    "best_models = {}  # Dizionario per memorizzare i migliori modelli per ciascun cliente\n",
    "\n",
    "for epoch in range(EPOCHS):        \n",
    "    index.append(epoch)\n",
    "    \n",
    "    #################### copy fed model ###################\n",
    "    copy_fed(CLIENTS, nets, fed_name='global')\n",
    "    \n",
    "    #### conduct training #####\n",
    "    for client, supervision_t in zip(CLIENTS, CLIENTS_SUPERVISION):\n",
    "        train_model(training_clients[client], nets[client], \\\n",
    "                                  optimizers[client], device, \\\n",
    "                                  acc = acc_train[client], \\\n",
    "                                  loss = loss_train[client], \\\n",
    "                                  supervision_type = supervision_t)\n",
    "        \n",
    "    aggr_fed(CLIENTS, WEIGHTS, nets, fed_name='global')\n",
    "    ################### test ##############################\n",
    "    avg_acc = 0.0\n",
    "    for client in CLIENTS:\n",
    "        test(epoch, testing_clients[client], nets['global'], device, acc_test[client],\\\n",
    "             loss_test[client])\n",
    "        avg_acc += acc_test[client][-1]\n",
    "        \n",
    "        # Salva il modello se l'accuratezza del cliente migliora\n",
    "        if acc_test[client][-1] > best_models.get(client, {'accuracy': 0})['accuracy']:\n",
    "            best_models[client] = {'model': nets[client].state_dict(), 'accuracy': acc_test[client][-1]}\n",
    "            torch.save(nets[client].state_dict(), os.path.join(best_model_dir, f\"best_model_{client}.pt\"))\n",
    "        \n",
    "    avg_acc = avg_acc / TOTAL_CLIENTS\n",
    "    ############################################################\n",
    "    ########################################################\n",
    "    if avg_acc > best_avg_acc:\n",
    "        best_avg_acc = avg_acc\n",
    "        best_epoch = epoch\n",
    "    \n",
    "    ################################\n",
    "    # plot #########################\n",
    "    ################################\n",
    "    clear_output(wait=True)\n",
    "    print(\"Epoch:\", epoch, \"/\", EPOCHS)\n",
    "    print(\"Current Average Accuracy:\", avg_acc, \"Best Average Accuracy:\", best_avg_acc)\n",
    "    plot_graphs(0, CLIENTS, index, acc_train, 'acc_train')\n",
    "    plot_graphs(1, CLIENTS, index, loss_train, 'loss_train')\n",
    "    plot_graphs(2, CLIENTS, index, acc_test, ' acc_test')\n",
    "\n",
    "print(\"Best Average Accuracy:\", best_avg_acc, \"at Epoch:\", best_epoch)\n",
    "for client in CLIENTS:\n",
    "    print(client)\n",
    "    tmp = best_epoch\n",
    "    best_epoch = best_epoch \n",
    "    print(\"shared epoch specific\")\n",
    "    print(acc_test[client][best_epoch])\n",
    "    print(\"max client-specific\")\n",
    "    print(np.max(acc_test[client]))\n",
    "    best_epoch = tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9236aee-ddba-4d3e-8301-503094d9cd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Funzione per caricare un'immagine di test\n",
    "def load_test_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    return image\n",
    "\n",
    "# Funzione per visualizzare l'immagine e la segmentazione ottenuta dal modello\n",
    "def visualize(image, segmentation):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    axes[0].imshow(image)\n",
    "    axes[0].set_title('Test Image')\n",
    "    axes[0].axis('off')\n",
    "    axes[1].imshow(segmentation, cmap='gray')\n",
    "    axes[1].set_title('Segmentation')\n",
    "    axes[1].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Percorso della directory contenente i modelli salvati\n",
    "saved_models_dir = \"C:\\\\Users\\\\utente\\\\Desktop\"\n",
    "\n",
    "# Cliente per cui è stato salvato il modello\n",
    "client = \"miccai\"\n",
    "\n",
    "# Carica il modello salvato per il cliente specificato\n",
    "model_path = os.path.join(saved_models_dir, f\"best_model_{client}.pt\")\n",
    "if os.path.exists(model_path):\n",
    "    model = YourModel()  # Sostituisci YourModel() con la classe/modello specifico che hai utilizzato\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "else:\n",
    "    print(f\"Model for client {client} not found at {model_path}\")\n",
    "\n",
    "# Percorso dell'immagine di test\n",
    "test_image_path = \"C:\\Users\\utente\\Desktop\\Università\\Tesi magistrale\\RC Nuclei Cellulari\\RC_Nuclei\\Nuclei_Segmentation_Experiments_Demo_dataset\\MICCAI2017\\Nuclei_segmentation_testing\\imagesTs\\image02.png\"  # Sostituisci con il percorso dell'immagine di test\n",
    "\n",
    "# Carica l'immagine di test\n",
    "test_image = load_test_image(test_image_path)\n",
    "\n",
    "# Esegui la segmentazione sull'immagine di test utilizzando il modello caricato\n",
    "if model:\n",
    "    # Assicurati di adattare questa parte del codice in base alla tua implementazione specifica\n",
    "    with torch.no_grad():\n",
    "        # Preprocessa l'immagine di test se necessario\n",
    "        preprocessed_image = preprocess(test_image)\n",
    "        # Effettua la segmentazione\n",
    "        segmentation_output = model(preprocessed_image)\n",
    "        # Postprocessa la segmentazione se necessario\n",
    "        postprocessed_segmentation = postprocess(segmentation_output)\n",
    "    \n",
    "    # Visualizza l'immagine di test e la segmentazione ottenuta\n",
    "    visualize(test_image, postprocessed_segmentation)\n",
    "else:\n",
    "    print(\"Model not found for client 'miccai'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
