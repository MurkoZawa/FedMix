{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f014caf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import functional as F\n",
    "from unet import UNet\n",
    "from dice_loss import dice_coeff\n",
    "####################################################\n",
    "# for data splitting\n",
    "####################################################\n",
    "import pandas as pd\n",
    "####################################################\n",
    "# for data preparation\n",
    "####################################################\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, balanced_accuracy_score\n",
    "####################################################\n",
    "# for plotting\n",
    "####################################################\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import random\n",
    "############################\n",
    "# Helper func\n",
    "############################\n",
    "from helper import * \n",
    "\n",
    "########################################\n",
    "N_CHANNELS = 1 #greyscale\n",
    "N_CLASSES = 1 # classes, IRF, SRF, PED\n",
    "\n",
    "BATCH_SIZE, EPOCHS = 16, 150\n",
    "IMAGE_SIZE = (224, 224)\n",
    "CROP_SIZE = (200, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b4c626c-ff9f-4e18-a942-2cd05157a3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9748743718592965\n",
      "0.9722222222222222\n"
     ]
    }
   ],
   "source": [
    "PTH = r'C:\\Users\\utente\\Desktop\\Università\\Tesi magistrale\\FedMix\\data\\labelsTrBW'\n",
    "PTH_IM = r'C:\\Users\\utente\\Desktop\\Università\\Tesi magistrale\\FedMix\\data\\imagesTrAug'\n",
    "\n",
    "miccai_ = np.arange(1,200)\n",
    "bns_ = np.arange(200,380)\n",
    "\n",
    "miccai_test = np.random.choice(miccai_, size=5, replace=False)\n",
    "miccai_test = [str(a) for a in miccai_test]\n",
    "miccai_train = [str(a) for a in miccai_ if str(a) not in miccai_test]\n",
    "print(len(miccai_train)/len(miccai_))\n",
    "\n",
    "bns_test = np.random.choice(bns_, size=5, replace=False)\n",
    "bns_test = [str(a) for a in bns_test]\n",
    "bns_train = [str(a) for a in bns_ if str(a) not in bns_test]\n",
    "print(len(bns_train)/len(bns_))\n",
    "\n",
    "whole_data =  os.listdir(PTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "feefc4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SPLIT = dict()\n",
    "TEST_SPLIT['miccai'] = miccai_test\n",
    "TEST_SPLIT['bns'] = bns_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a34d0dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "WHOLE_DATA_TRAIN = dict()\n",
    "WHOLE_DATA_TEST = dict()\n",
    "\n",
    "WHOLE_DATA_TRAIN['miccai'] = []\n",
    "WHOLE_DATA_TRAIN['bns'] = []\n",
    "\n",
    "WHOLE_DATA_TEST['miccai'] = []\n",
    "WHOLE_DATA_TEST['bns'] = []\n",
    "\n",
    "import random\n",
    "\n",
    "# Calcola il numero totale di campioni\n",
    "total_samples = len(whole_data)\n",
    "\n",
    "# Calcola il numero di campioni da utilizzare per il test\n",
    "test_size = int(0.1 * total_samples)\n",
    "\n",
    "# Estrai casualmente un subset di campioni per il test\n",
    "test_samples = random.sample(whole_data, test_size)\n",
    "\n",
    "# Itera attraverso i dati e assegna le immagini e le label al set di test se sono presenti nei campioni selezionati\n",
    "for item in whole_data:\n",
    "    separator = item.split('_') # Identifica la fonte\n",
    "    sample_number = separator[1].split('0')[-1]\n",
    "    \n",
    "    # Controlla se l'elemento corrente è presente nei campioni di test\n",
    "    if item in test_samples:\n",
    "        # Aggiungi l'elemento al set di test\n",
    "        data_path = (PTH_IM+'\\\\'+item, PTH+'\\\\'+item) # X,Y source\n",
    "        WHOLE_DATA_TEST[separator[0]].append(data_path)\n",
    "    else:\n",
    "        # Aggiungi l'elemento al set di allenamento\n",
    "        data_path = (PTH_IM+'\\\\'+item, PTH+'\\\\'+item) # X,Y source\n",
    "        WHOLE_DATA_TRAIN[separator[0]].append(data_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eab83d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name\t\t train\t test\n",
      "miccai \t\t 181 \t 19\n",
      "bns \t 323 \t 37\n"
     ]
    }
   ],
   "source": [
    "LEN_bns = 0\n",
    "print('name\\t\\t train\\t test')\n",
    "for item in WHOLE_DATA_TRAIN:\n",
    "    if item == 'bns':\n",
    "        print(item,'\\t', len(WHOLE_DATA_TRAIN[item]),'\\t', len(WHOLE_DATA_TEST[item]))\n",
    "        LEN_bns = WHOLE_DATA_TRAIN[item]\n",
    "    else:\n",
    "        print(item,'\\t\\t', len(WHOLE_DATA_TRAIN[item]),'\\t', len(WHOLE_DATA_TEST[item]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67948c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "\n",
    "WEIGHTS_CL = [0.0,0.0]\n",
    "CLIENTS = ['miccai', 'bns']\n",
    "CLIENTS_2 = [cl +'_2' for cl in CLIENTS]\n",
    "TOTAL_CLIENTS = len(CLIENTS)\n",
    "\n",
    "LR = 1.5e-3\n",
    "WD = 1e-5\n",
    "TH = 0.9\n",
    "\n",
    "LAMBDA_ =2\n",
    "BETA_=3\n",
    "TH = 0.9\n",
    "\n",
    "for idx, client in enumerate(WHOLE_DATA_TRAIN):\n",
    "    WEIGHTS_CL[idx] = len(WHOLE_DATA_TRAIN[client])\n",
    "\n",
    "    \n",
    "total_weight = sum(WEIGHTS_CL)\n",
    "WEIGHTS_CL = [s/total_weight for s in WEIGHTS_CL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8144b2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENTS_SUPERVISION = ['labeled', 'labeled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d4ad07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dataset = dict()\n",
    "for cl in CLIENTS:\n",
    "    split_dataset[cl+'_train'] = retouch(WHOLE_DATA_TRAIN[cl], train=True)\n",
    "    split_dataset[cl+'_test'] = retouch(WHOLE_DATA_TEST[cl], train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "777da8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_CLIENTS = 2\n",
    "GLOBAL_ACC = 0.0\n",
    "\n",
    "training_clients, testing_clients = dict(), dict()\n",
    "########## aditional #####################\n",
    "training_clients_pl = dict()\n",
    "acc_train, acc_test, loss_train, loss_test = dict(), dict(), \\\n",
    "                                            dict(), dict()\n",
    "\n",
    "nets, optimizers = dict(), dict()\n",
    "\n",
    "nets['global'] = UNet(n_channels=N_CHANNELS, n_classes=N_CLASSES, \\\n",
    "                      bilinear=True).to(device)\n",
    "\n",
    "nets['global_2'] = UNet(n_channels=N_CHANNELS, n_classes=N_CLASSES, \\\n",
    "                      bilinear=True).to(device)\n",
    "\n",
    "for client, c_sup in zip(CLIENTS, CLIENTS_SUPERVISION):\n",
    "    if c_sup == 'labeled':\n",
    "        training_clients[client] = DataLoader(split_dataset[client+'_train'], batch_size=16,\\\n",
    "                     shuffle=True, num_workers=8)\n",
    "        training_clients_pl[client] = DataLoader(split_dataset[client+'_train'], batch_size=1, \\\n",
    "                    shuffle=True, num_workers=8)\n",
    "    else:\n",
    "        training_clients[client] = DataLoader(split_dataset[client+'_train'], batch_size=16,\\\n",
    "                             shuffle=True, num_workers=8)\n",
    "        ################# additional dataloader ##########################################\n",
    "        training_clients_pl[client] = DataLoader(split_dataset[client+'_train'], batch_size=1,\\\n",
    "                             shuffle=True, num_workers=8)\n",
    "        training_clients_pl[client+'_2'] = DataLoader(split_dataset[client+'_train'], batch_size=1,\\\n",
    "                             shuffle=True, num_workers=8)\n",
    "    ###################################################################################\n",
    "    testing_clients[client] = DataLoader(split_dataset[client+'_test'], batch_size=16,\\\n",
    "                         shuffle=False, num_workers=1)\n",
    "    \n",
    "    acc_train[client], acc_test[client] = [], []\n",
    "    loss_train[client], loss_test[client] = [], []\n",
    "        \n",
    "    nets[client] = UNet(n_channels=N_CHANNELS, n_classes=N_CLASSES, \\\n",
    "                      bilinear=True).to(device)\n",
    "    nets[client+'_2'] = UNet(n_channels=N_CHANNELS, n_classes=N_CLASSES, \\\n",
    "                      bilinear=True).to(device)\n",
    "    optimizers[client]= optim.Adam(nets[client].parameters(), \\\n",
    "                                   lr=LR,weight_decay=WD)\n",
    "    optimizers[client+'_2']= optim.Adam(nets[client+'_2'].parameters(), \\\n",
    "                                   lr=LR,weight_decay=WD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7805103e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.multiprocessing.set_sharing_strategy('file_system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98a18193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.35912698412698413, 0.6408730158730159]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WEIGHTS_CL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73e8fc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miccai\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m client, supervision_t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(CLIENTS, CLIENTS_SUPERVISION):\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(client)\n\u001b[1;32m---> 16\u001b[0m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_clients\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m                              \u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m                              \u001b[49m\u001b[43macc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43macc_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mloss_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m                              \u001b[49m\u001b[43msupervision_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msupervision_t\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m aggr_fed(CLIENTS, WEIGHTS_CL, nets, fed_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglobal\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m################### test ##############################\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\Università\\Tesi magistrale\\FedMix\\helper.py:448\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(trainloader, net_stu, optimizer_stu, device, acc, loss, supervision_type, warmup, CE_LOSS, FedMix_network)\u001b[0m\n\u001b[0;32m    446\u001b[0m labeled_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(trainloader)\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(labeled_len):\n\u001b[1;32m--> 448\u001b[0m     imgs, masks, y_pl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(labeled_iter)\n\u001b[0;32m    449\u001b[0m     imgs, masks \u001b[38;5;241m=\u001b[39m imgs\u001b[38;5;241m.\u001b[39mto(device), masks\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    450\u001b[0m     optimizer_stu\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "best_avg_acc, best_epoch_avg = 0,0\n",
    "index = []\n",
    "\n",
    "for client in CLIENTS:\n",
    "    acc_train[client], acc_test[client] = [], []\n",
    "    loss_train[client], loss_test[client] = [], [] \n",
    "    \n",
    "for epoch in range(EPOCHS):\n",
    "    index.append(epoch)\n",
    "    ####### conduct training #####\n",
    "    #################### copy fed model ###################\n",
    "    copy_fed(CLIENTS, nets, fed_name='global')\n",
    "    \n",
    "    for client, supervision_t in zip(CLIENTS, CLIENTS_SUPERVISION):\n",
    "        print(client)\n",
    "        train_model(training_clients[client], nets[client], \\\n",
    "                                  optimizers[client], device, \\\n",
    "                                  acc = acc_train[client], \\\n",
    "                                  loss = loss_train[client], \\\n",
    "                                  supervision_type = supervision_t)\n",
    "        \n",
    "    aggr_fed(CLIENTS, WEIGHTS_CL, nets, fed_name='global')\n",
    "    ################### test ##############################\n",
    "    avg_acc = 0.0\n",
    "    for client in CLIENTS:\n",
    "        test(epoch, testing_clients[client], nets[client], device, acc_test[client],\\\n",
    "             loss_test[client])\n",
    "        avg_acc += acc_test[client][-1]\n",
    "        \n",
    "    avg_acc = avg_acc / TOTAL_CLIENTS\n",
    "    ############################################################\n",
    "    ########################################################\n",
    "    if avg_acc > best_avg_acc:\n",
    "        best_avg_acc = avg_acc\n",
    "        best_epoch = epoch\n",
    "    \n",
    "    ################################\n",
    "    # plot #########################\n",
    "    ################################\n",
    "    clear_output(wait=True)\n",
    "    print(avg_acc, best_avg_acc)\n",
    "    plot_graphs(0, CLIENTS, index, acc_train, 'acc_train')\n",
    "    plot_graphs(1, CLIENTS, index, loss_train, 'loss_train')\n",
    "    plot_graphs(2, CLIENTS, index, acc_test, ' acc_test')\n",
    "\n",
    "print(best_avg_acc, best_epoch)\n",
    "for client in CLIENTS:\n",
    "    print(client)\n",
    "    tmp = best_epoch\n",
    "    best_epoch = best_epoch \n",
    "    print(\"shared epoch specific\")\n",
    "    print(acc_test[client][best_epoch])\n",
    "    print(\"max client-specific\")\n",
    "    print(np.max(acc_test[client]))\n",
    "    best_epoch = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f6deb95-5f40-4412-925e-6bd9e86c7992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1\n",
      "Forma del tensore: torch.Size([16, 1, 200, 200])\n",
      "Forma del tensore: torch.Size([16, 3, 200, 200])\n",
      "Forma del tensore: torch.Size([16, 3, 200, 200])\n",
      "Forma del tensore: torch.Size([16, 3, 200, 200])\n",
      "Batch: 2\n",
      "Forma del tensore: torch.Size([16, 1, 200, 200])\n",
      "Forma del tensore: torch.Size([16, 3, 200, 200])\n",
      "Forma del tensore: torch.Size([16, 3, 200, 200])\n",
      "Forma del tensore: torch.Size([16, 3, 200, 200])\n",
      "Batch: 3\n",
      "Forma del tensore: torch.Size([16, 1, 200, 200])\n",
      "Forma del tensore: torch.Size([16, 3, 200, 200])\n",
      "Forma del tensore: torch.Size([16, 3, 200, 200])\n",
      "Forma del tensore: torch.Size([16, 3, 200, 200])\n",
      "Batch: 4\n",
      "Forma del tensore: torch.Size([16, 1, 200, 200])\n",
      "Forma del tensore: torch.Size([16, 3, 200, 200])\n",
      "Forma del tensore: torch.Size([16, 3, 200, 200])\n",
      "Forma del tensore: torch.Size([16, 3, 200, 200])\n",
      "Batch: 5\n",
      "Forma del tensore: torch.Size([16, 1, 200, 200])\n",
      "Forma del tensore: torch.Size([16, 3, 200, 200])\n",
      "Forma del tensore: torch.Size([16, 3, 200, 200])\n",
      "Forma del tensore: torch.Size([16, 3, 200, 200])\n",
      "Batch: 6\n",
      "Forma del tensore: torch.Size([16, 1, 200, 200])\n",
      "Forma del tensore: torch.Size([16, 3, 200, 200])\n",
      "Forma del tensore: torch.Size([16, 3, 200, 200])\n",
      "Forma del tensore: torch.Size([16, 3, 200, 200])\n",
      "Batch: 7\n",
      "Forma del tensore: torch.Size([16, 1, 200, 200])\n",
      "Forma del tensore: torch.Size([16, 3, 200, 200])\n",
      "Forma del tensore: torch.Size([16, 3, 200, 200])\n",
      "Forma del tensore: torch.Size([16, 3, 200, 200])\n",
      "Batch: 8\n",
      "Forma del tensore: torch.Size([16, 1, 200, 200])\n",
      "Forma del tensore: torch.Size([16, 3, 200, 200])\n",
      "Forma del tensore: torch.Size([16, 3, 200, 200])\n",
      "Forma del tensore: torch.Size([16, 3, 200, 200])\n",
      "Batch: 9\n",
      "Forma del tensore: torch.Size([16, 1, 200, 200])\n",
      "Forma del tensore: torch.Size([16, 3, 200, 200])\n",
      "Forma del tensore: torch.Size([16, 3, 200, 200])\n",
      "Forma del tensore: torch.Size([16, 3, 200, 200])\n",
      "Batch: 10\n",
      "Forma del tensore: torch.Size([16, 1, 200, 200])\n",
      "Forma del tensore: torch.Size([16, 3, 200, 200])\n",
      "Forma del tensore: torch.Size([16, 3, 200, 200])\n",
      "Forma del tensore: torch.Size([16, 3, 200, 200])\n",
      "Batch: 11\n",
      "Forma del tensore: torch.Size([16, 1, 200, 200])\n",
      "Forma del tensore: torch.Size([16, 3, 200, 200])\n",
      "Forma del tensore: torch.Size([16, 3, 200, 200])\n",
      "Forma del tensore: torch.Size([16, 3, 200, 200])\n",
      "Batch: 12\n",
      "Forma del tensore: torch.Size([5, 1, 200, 200])\n",
      "Forma del tensore: torch.Size([5, 3, 200, 200])\n",
      "Forma del tensore: torch.Size([5, 3, 200, 200])\n",
      "Forma del tensore: torch.Size([5, 3, 200, 200])\n"
     ]
    }
   ],
   "source": [
    "# Stampa un batch completo\n",
    "for batch_idx, batch in enumerate(training_clients[client]):\n",
    "    print(\"Batch:\", batch_idx + 1)\n",
    "    for data in batch:\n",
    "        print(\"Forma del tensore:\", data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fd9309-2dcb-4b23-aeb7-0654f4ef7cb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
